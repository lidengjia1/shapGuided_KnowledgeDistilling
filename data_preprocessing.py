"""
æ•°æ®é¢„å¤„ç†æ¨¡å—
Data Preprocessing Module
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

class DataPreprocessor:
    """æ•°æ®é¢„å¤„ç†ç±»"""
    
    def __init__(self):
        self.scalers = {}
        self.encoders = {}
        self.feature_mappings = self._create_feature_mappings()
    
    def _create_feature_mappings(self):
        """åˆ›å»ºçœŸå®ç‰¹å¾åæ˜ å°„"""
        return {
            'german': {
                'Status': 'Account_Status',
                'Duration': 'Loan_Duration_Months', 
                'Credit_history': 'Credit_History',
                'Purpose': 'Loan_Purpose',
                'Credit_amount': 'Credit_Amount',
                'Savings': 'Savings_Account',
                'Employment': 'Employment_Duration',
                'Installment_rate': 'Installment_Rate',
                'Personal_status': 'Personal_Status_Sex',
                'Other_parties': 'Other_Debtors',
                'Residence_since': 'Residence_Duration',
                'Property_magnitude': 'Property_Type',
                'Age': 'Age_Years',
                'Other_payment_plans': 'Other_Installment_Plans',
                'Housing': 'Housing_Type',
                'Existing_credits': 'Existing_Credits_Count',
                'Job': 'Job_Type',
                'Num_dependents': 'Dependents_Count',
                'Own_telephone': 'Telephone_Owner',
                'Foreign_worker': 'Foreign_Worker'
            },
            'australian': {f'feature_{i}': f'Feature_{i+1}' for i in range(14)},
            'uci': {
                'X1': 'Credit_Limit',
                'X2': 'Gender', 
                'X3': 'Education',
                'X4': 'Marriage',
                'X5': 'Age',
                'X6': 'Payment_Status_Sep',
                'X7': 'Payment_Status_Aug',
                'X8': 'Payment_Status_Jul',
                'X9': 'Payment_Status_Jun',
                'X10': 'Payment_Status_May',
                'X11': 'Payment_Status_Apr',
                'X12': 'Bill_Amount_Sep',
                'X13': 'Bill_Amount_Aug',
                'X14': 'Bill_Amount_Jul',
                'X15': 'Bill_Amount_Jun',
                'X16': 'Bill_Amount_May',
                'X17': 'Bill_Amount_Apr',
                'X18': 'Payment_Amount_Sep',
                'X19': 'Payment_Amount_Aug',
                'X20': 'Payment_Amount_Jul',
                'X21': 'Payment_Amount_Jun',
                'X22': 'Payment_Amount_May',
                'X23': 'Payment_Amount_Apr'
            }
        }
    
    def load_and_preprocess_data(self):
        """åŠ è½½å¹¶é¢„å¤„ç†ä¸‰ä¸ªæ•°æ®é›†"""
        print("ğŸ”„ Loading and preprocessing datasets...")
        
        # 1. German Credit Dataset
        german_df = pd.read_csv('data/german_credit.csv')
        print(f"German Credit original shape: {german_df.shape}")
        
        # å¤„ç†åˆ†ç±»å˜é‡
        categorical_cols = ['Status', 'Credit_history', 'Purpose', 'Savings', 'Employment', 
                          'Personal_status', 'Other_parties', 'Property_magnitude', 
                          'Other_payment_plans', 'Housing', 'Job', 'Own_telephone', 'Foreign_worker']
        
        german_processed = german_df.copy()
        for col in categorical_cols:
            if col in german_processed.columns:
                le = LabelEncoder()
                german_processed[col] = le.fit_transform(german_processed[col].astype(str))
                self.encoders[f'german_{col}'] = le
        
        # è½¬æ¢æ ‡ç­¾ï¼š1->0, 2->1
        german_processed['Class'] = german_processed['Class'] - 1
        
        # 2. Australian Credit Dataset
        australian_df = pd.read_csv('data/australian_credit.csv')
        print(f"Australian Credit original shape: {australian_df.shape}")
        australian_processed = australian_df.copy()
        
        # 3. UCI Credit Dataset
        uci_df = pd.read_excel('data/uci_credit.xls')
        print(f"UCI Credit original shape: {uci_df.shape}")
        
        # å»é™¤ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜è¡Œï¼‰å’ŒIDåˆ—
        uci_df = uci_df.iloc[1:].reset_index(drop=True)
        uci_df = uci_df.drop('Unnamed: 0', axis=1, errors='ignore')
        
        # é‡å‘½ååˆ—å
        feature_cols = [f'X{i}' for i in range(1, len(uci_df.columns))]
        uci_df.columns = feature_cols + ['Y']
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        for col in uci_df.columns:
            uci_df[col] = pd.to_numeric(uci_df[col], errors='coerce')
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        uci_df = uci_df.dropna().reset_index(drop=True)
        
        # æ ‡ç­¾åˆ—é‡å‘½åä¸ºClass
        uci_processed = uci_df.rename(columns={'Y': 'Class'})
        
        print(f"German Credit processed shape: {german_processed.shape}")
        print(f"Australian Credit processed shape: {australian_processed.shape}")
        print(f"UCI Credit processed shape: {uci_processed.shape}")
        
        return {
            'german': german_processed,
            'australian': australian_processed,
            'uci': uci_processed
        }
    
    def split_and_scale_data(self, df, dataset_name):
        """åˆ’åˆ†å¹¶æ ‡å‡†åŒ–æ•°æ® (6:2:2)"""
        X = df.drop('Class', axis=1).values
        y = df['Class'].values
        
        # ç¬¬ä¸€æ¬¡åˆ’åˆ†ï¼šè®­ç»ƒé›†(60%) vs ä¸´æ—¶é›†(40%)
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, test_size=0.4, random_state=RANDOM_SEED, stratify=y
        )
        
        # ç¬¬äºŒæ¬¡åˆ’åˆ†ï¼šéªŒè¯é›†(20%) vs æµ‹è¯•é›†(20%)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=y_temp
        )
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers[dataset_name] = scaler
        
        # è·å–åŸå§‹ç‰¹å¾å
        original_feature_names = list(df.drop('Class', axis=1).columns)
        
        # æ˜ å°„åˆ°çœŸå®ç‰¹å¾å
        feature_mapping = self.feature_mappings.get(dataset_name, {})
        real_feature_names = [feature_mapping.get(name, name) for name in original_feature_names]
        
        print(f"{dataset_name} dataset split:")
        print(f"  Train: {X_train_scaled.shape}, Val: {X_val_scaled.shape}, Test: {X_test_scaled.shape}")
        print(f"  Class distribution - Train: {np.bincount(y_train)}, Val: {np.bincount(y_val)}, Test: {np.bincount(y_test)}")
        
        return {
            'X_train': X_train_scaled,
            'X_val': X_val_scaled,
            'X_test': X_test_scaled,
            'y_train': y_train,
            'y_val': y_val,
            'y_test': y_test,
            'feature_names': real_feature_names,
            'original_feature_names': original_feature_names
        }
    
    def process_all_datasets(self):
        """å¤„ç†æ‰€æœ‰æ•°æ®é›†å¹¶è¿”å›å¤„ç†åçš„æ•°æ®"""
        print("ğŸ“Š Processing all datasets...")
        
        # åŠ è½½å’Œé¢„å¤„ç†åŸå§‹æ•°æ®
        raw_datasets = self.load_and_preprocess_data()
        
        # å¤„ç†æ¯ä¸ªæ•°æ®é›†
        processed_datasets = {}
        for dataset_name, df in raw_datasets.items():
            print(f"\nğŸ”§ Processing {dataset_name} dataset...")
            processed_datasets[dataset_name] = self.split_and_scale_data(df, dataset_name)
        
        print("\nâœ… All datasets processed successfully!")
        return processed_datasets
