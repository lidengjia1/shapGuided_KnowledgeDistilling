"""
SHAPç‰¹å¾é‡è¦æ€§åˆ†ææ¨¡å—
SHAP Feature Importance Analysis Module
"""

import numpy as np
# è®¾ç½®matplotlibåç«¯ä¸ºéäº¤äº’å¼ï¼Œé¿å…å¤šçº¿ç¨‹é—®é¢˜
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import warnings
import optuna
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
warnings.filterwarnings('ignore')

# ç¦ç”¨Optunaæ—¥å¿—è¾“å‡º
optuna.logging.set_verbosity(optuna.logging.WARNING)

plt.style.use('default')

class SHAPAnalyzer:
    """SHAPç‰¹å¾é‡è¦æ€§åˆ†æå™¨ - åŸºäºå†³ç­–æ ‘æ¨¡å‹"""
    
    def __init__(self, processed_data):
        self.processed_data = processed_data
        self.decision_tree_models = {}
        
    def train_decision_trees(self):
        """ä¸ºæ¯ä¸ªæ•°æ®é›†è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ç”¨äºSHAPåˆ†æ"""
        print("ğŸŒ³ Training decision trees for SHAP analysis...")
        
        for dataset_name, data_dict in self.processed_data.items():
            print(f"   Training decision tree for {dataset_name}...")
            
            X_train = data_dict['X_train']
            X_test = data_dict['X_test']
            y_train = data_dict['y_train']
            y_test = data_dict['y_test']
            
            # ä½¿ç”¨Optunaä¼˜åŒ–å†³ç­–æ ‘å‚æ•°
            def objective(trial):
                # å®šä¹‰è¶…å‚æ•°æœç´¢ç©ºé—´
                max_depth = trial.suggest_int('max_depth', 5, 25)
                min_samples_split = trial.suggest_int('min_samples_split', 2, 20)
                min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)
                
                # åˆ›å»ºå†³ç­–æ ‘æ¨¡å‹
                dt = DecisionTreeClassifier(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    min_samples_leaf=min_samples_leaf,
                    random_state=42
                )
                
                # ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹
                scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='accuracy', n_jobs=1)
                return scores.mean()
            
            # åˆ›å»ºOptuna studyå¹¶ä¼˜åŒ–
            study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))
            study.optimize(objective, n_trials=50, show_progress_bar=False)
            
            # ä½¿ç”¨æœ€ä½³å‚æ•°è®­ç»ƒæœ€ç»ˆæ¨¡å‹
            best_params = study.best_params
            best_model = DecisionTreeClassifier(
                max_depth=best_params['max_depth'],
                min_samples_split=best_params['min_samples_split'],
                min_samples_leaf=best_params['min_samples_leaf'],
                random_state=42
            )
            best_model.fit(X_train, y_train)
            
            # è®¡ç®—æµ‹è¯•é›†å‡†ç¡®ç‡
            y_pred = best_model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            
            self.decision_tree_models[dataset_name] = {
                'model': best_model,
                'accuracy': accuracy,
                'best_params': best_params,
                'best_score': study.best_value
            }
            
            print(f"     Decision tree accuracy: {accuracy:.4f}")
            print(f"     Best params: {best_params}")
            print(f"     CV score: {study.best_value:.4f}")
        
        print("âœ… Decision trees trained for SHAP analysis")
        
    def compute_shap_values(self, dataset_name, top_k_range=(5, 8)):
        """ä½¿ç”¨å†³ç­–æ ‘æ¨¡å‹è®¡ç®—SHAPå€¼å¹¶é€‰æ‹©é‡è¦ç‰¹å¾
        
        SHAPè®¡ç®—æ–¹æ³•è¯´æ˜ï¼š
        1. ä½¿ç”¨è®­ç»ƒå¥½çš„å†³ç­–æ ‘æ¨¡å‹è¿›è¡ŒSHAPåˆ†æ
        2. ä½¿ç”¨SHAP TreeExplainerä¸“é—¨é’ˆå¯¹æ ‘æ¨¡å‹ä¼˜åŒ–
        3. å¯¹å…¨é‡æ•°æ®æ ·æœ¬(è®­ç»ƒ+æµ‹è¯•)è®¡ç®—SHAPå€¼ä»¥è·å¾—æ›´å‡†ç¡®çš„ç‰¹å¾é‡è¦æ€§
        4. SHAPå€¼è¡¨ç¤ºæ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®åº¦
        5. é€šè¿‡å¹³å‡ç»å¯¹SHAPå€¼è®¡ç®—ç‰¹å¾é‡è¦æ€§æ’åº
        """
        print(f"\nğŸ” Computing SHAP values for {dataset_name.upper()} dataset...")
        print(f"   Method: TreeExplainer with decision tree model")
        print(f"   Computing SHAP for all data samples (train + test)")
        
        model_info = self.decision_tree_models[dataset_name]
        model = model_info['model']
        data_dict = self.processed_data[dataset_name]
        
        # å‡†å¤‡æ•°æ® - ä½¿ç”¨å…¨é‡æ ·æœ¬(è®­ç»ƒ+æµ‹è¯•)
        X_train = data_dict['X_train']
        X_test = data_dict['X_test']
        
        # åˆå¹¶è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä»¥è·å¾—æ›´å…¨é¢çš„SHAPåˆ†æ
        import numpy as np
        X_all = np.vstack([X_train, X_test])
        
        print(f"   Data samples: {X_train.shape[0]} train + {X_test.shape[0]} test = {X_all.shape[0]} total")
        
        # åˆ›å»ºSHAP TreeExplainer
        explainer = shap.TreeExplainer(model)
        
        # è®¡ç®—SHAPå€¼
        print(f"   Calculating SHAP values for {X_all.shape[0]} samples...")
        shap_values = explainer.shap_values(X_all)
        
        # å¤„ç†ä¸åŒæ ¼å¼çš„SHAPè¾“å‡º
        if isinstance(shap_values, list):
            # äºŒåˆ†ç±»é—®é¢˜ï¼Œé€šå¸¸å–ç¬¬äºŒä¸ªç±»åˆ«ï¼ˆæ­£ç±»ï¼‰
            if len(shap_values) == 2:
                shap_values = shap_values[1]
            else:
                shap_values = shap_values[0]
        
        # è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆå¹³å‡ç»å¯¹SHAPå€¼ï¼‰
        feature_importance = np.mean(np.abs(shap_values), axis=0)
        
        # ç¡®ä¿feature_importanceæ˜¯ä¸€ç»´æ•°ç»„å¹¶è½¬æ¢ä¸ºfloat
        if feature_importance.ndim > 1:
            feature_importance = feature_importance.flatten()
        feature_importance = feature_importance.astype(float)
        
        # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
        feature_names = data_dict['feature_names']
        importance_dict = dict(zip(feature_names, feature_importance))
        
        # æŒ‰é‡è¦æ€§æ’åº
        sorted_features = sorted(importance_dict.items(), key=lambda x: float(x[1]), reverse=True)
        
        print(f"   Top 8 important features for {dataset_name}:")
        for i, (feature, importance) in enumerate(sorted_features[:8]):
            print(f"     {i+1}. {feature}: {float(importance):.4f}")
        
        # ç”Ÿæˆä¸åŒtop-kçš„ç‰¹å¾é€‰æ‹©
        top_k_features = {}
        for k in range(top_k_range[0], top_k_range[1] + 1):
            top_k_features[k] = [feat[0] for feat in sorted_features[:k]]
        
        return {
            'shap_values': shap_values,
            'feature_importance': feature_importance,
            'sorted_features': sorted_features,
            'top_k_features': top_k_features,
            'explainer': explainer,
            'feature_names': feature_names
        }
    
    def create_combined_shap_visualization(self, all_shap_results):
        """åˆ›å»ºä¸‰ä¸ªæ•°æ®é›†çš„SHAPå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨"""
        print(f"ğŸ“Š Creating combined SHAP visualization...")
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        datasets = ['german', 'uci', 'australian']
        titles = ['German Credit Dataset', 'UCI Credit Dataset', 'Australian Credit Dataset']
        
        for idx, (dataset_name, title) in enumerate(zip(datasets, titles)):
            ax = axes[idx]
            shap_results = all_shap_results[dataset_name]
            
            # è·å–Top 8ç‰¹å¾
            top_features = shap_results['sorted_features'][:8]
            features, importances = zip(*top_features)
            importances = [float(x) for x in importances]
            
            # åˆ›å»ºæ¡å½¢å›¾
            bars = ax.barh(range(len(features)), importances, color=f'C{idx}')
            ax.set_yticks(range(len(features)))
            ax.set_yticklabels(features, fontsize=8)
            ax.set_xlabel('Mean |SHAP Value|', fontsize=10)
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.invert_yaxis()
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, imp) in enumerate(zip(bars, importances)):
                ax.text(bar.get_width() + max(importances)*0.01, bar.get_y() + bar.get_height()/2, 
                       f'{imp:.3f}', va='center', fontsize=7)
        
        plt.tight_layout()
        plt.savefig('results/combined_shap_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ… Combined SHAP visualization saved to: results/combined_shap_analysis.png")
        
        return 'results/combined_shap_analysis.png'
